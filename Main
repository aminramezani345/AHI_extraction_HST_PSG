***CAUTION:*** This email is not from a BCM Source. Only click links or open attachments you know are safe. 
________________________________________

!pip install transformers datasets evaluate
from transformers import AutoTokenizer
from transformers import AutoModelForQuestionAnswering
from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline

import os
import torch
import pandas as pd
import re
model_name = r"M:\Research\Razjouyan_J_VAFI_H-50294\Erstad\Amin\Codes\deepsetroberta-base-squad2"
nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
sample_folder_path = r"S:\\Research-data\\Sharafkhaneh Group\\H-35366 OSA\\Amin_AHI\\eachNote"

results_df  = pd.DataFrame(columns=['filename',
                                    'AHI value'
                            ])

k=0
if os.path.exists(sample_folder_path) and os.path.isdir(sample_folder_path):
    # List all files in the folder
    files = os.listdir(sample_folder_path)

    # Iterate through each file
    for file_name in files:
        # Check if the file is a text file
        if file_name.endswith(".txt"):
            file_path = os.path.join(sample_folder_path, file_name)
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                text = file.read()
                cleaned_text = re.sub(r'[^\w\s:.]', '', text)
                cleaned_text = re.sub(r'\n\s*\n', '\n', cleaned_text)
                cleaned_text = re.sub(r':', ' :', cleaned_text)
                cleaned_text = re.sub(r'\n\s*\n', '\n', cleaned_text)  
            # Process the text or do whatever you need to do with it
    
        except UnicodeDecodeError as e:
            print(f"UnicodeDecodeError for file: {file_path}")
            print(e)
            continue  # Continue to the next file
        except Exception as e:
            print(f"An error occurred for file: {file_path}")
            print(e)
            continue  # Continue to the next file


        QA_input = {
        'question': 'How much is the amount (number) of the AHI or Apnea Hypopnea Index?',
        'context': f"""
            {cleaned_text}
        """
        }
    
        AHI_value = nlp(QA_input)
            
        new_row = [
        {
            'filename': file_name,
            'AHI value': AHI_value['answer'],
             }
        ]
        results_df = pd.concat([results_df, pd.DataFrame(new_row)], ignore_index=True)
        k = k + 1
        print(k)
results_df.to_csv(r"S:\Research-data\Sharafkhaneh Group\H-35366 OSA\Amin_AHI\eachNoteOutput\AHI_output_roberta_01.csv")        

